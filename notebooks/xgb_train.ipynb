{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility \n",
    "import os\n",
    "import pickle\n",
    "import toml\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Additional\n",
    "from features.preprocessing import dataset_preprocessor, df_preprocessor\n",
    "from features.fake_news_classifier import TFIDFTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"../config.toml\"\n",
    "config = toml.load(CONFIG_PATH)\n",
    "\n",
    "global_cfg = config[\"global\"]\n",
    "headvec_cfg = config[\"headline_vectorizer\"]\n",
    "bodyvec_cfg = config[\"body_vectorizer\"]\n",
    "rel_params = config[\"rel_params\"]\n",
    "cls_params = config[\"cls_params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bodies = pd.read_csv(\"../data/bodies.csv\", )\n",
    "stances = pd.read_csv(\"../data/stances.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_preprocessor(bodies, stances)\n",
    "X, y = df[[\"article_body\", \"headline\"]], df[[\"stance\", \"relation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = global_cfg[\"test_size\"], random_state=global_cfg[\"random_state\"])\n",
    "X_train_rel, X_train_cls, y_train_rel, y_train_cls, train_cls_indices = dataset_preprocessor(X_train, y_train, label_encoder)\n",
    "X_test_rel, X_test_cls, y_test_rel, y_test_cls, test_cls_indices = dataset_preprocessor(X_test, y_test, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_vectorizer = TfidfVectorizer(analyzer=headvec_cfg[\"analyzer\"], stop_words=headvec_cfg[\"stop_words\"], \n",
    "                                      lowercase=headvec_cfg[\"lowercase\"], token_pattern=r'\\w+')\n",
    "body_vectorizer = TfidfVectorizer(analyzer=bodyvec_cfg[\"analyzer\"], stop_words=bodyvec_cfg[\"stop_words\"], \n",
    "                                  lowercase=bodyvec_cfg[\"lowercase\"], token_pattern=r'\\w+')\n",
    "tfidf_transform = TFIDFTransform(headline_vectorizer=headline_vectorizer, body_vectorizer=body_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rel_vec = tfidf_transform.fit_transform(X_train_rel)\n",
    "X_train_cls_vec = tfidf_transform.transform(X_train_cls)\n",
    "\n",
    "D_train_rel = xgb.DMatrix(X_train_rel_vec, label=y_train_rel)\n",
    "D_train_cls = xgb.DMatrix(X_train_cls_vec, label=y_train_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_PARAM_MULTIPLIER = 1 # Multiply base number of result configs\n",
    "\n",
    "# All param lists should be equal length\n",
    "# Base number of param configs is equal to the length of param lists\n",
    "depth = [6, 12, 20, 24]\n",
    "l_rate = [0.05, 0.1, 0.2, 0.3]\n",
    "colsample = [0.7, 0.8, 0.9, 1.0]\n",
    "subsample = [0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "array_rel_params = []\n",
    "array_cls_params = []\n",
    "for i in range(len(depth) * RANDOM_PARAM_MULTIPLIER):\n",
    "    np.random.seed(i)\n",
    "    array_rel_params.append(\n",
    "        {\n",
    "            \"eta\": np.random.choice(l_rate),\n",
    "            \"max_depth\": np.random.choice(depth),\n",
    "            \"colsample_bytree\": np.random.choice(colsample),\n",
    "            \"subsample\": np.random.choice(subsample)\n",
    "        }\n",
    "    )\n",
    "\n",
    "for i in range(len(depth) * RANDOM_PARAM_MULTIPLIER):\n",
    "    np.random.seed(i+1)\n",
    "    array_cls_params.append(\n",
    "        {\n",
    "            \"eta\": np.random.choice(l_rate),\n",
    "            \"max_depth\": np.random.choice(depth),\n",
    "            \"colsample_bytree\": np.random.choice(colsample),\n",
    "            \"subsample\": np.random.choice(subsample),\n",
    "            \"num_class\": 3\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'eta': 0.05, 'max_depth': 24, 'colsample_bytree': 0.8, 'subsample': 0.7},\n",
       " {'eta': 0.1, 'max_depth': 24, 'colsample_bytree': 0.7, 'subsample': 0.7},\n",
       " {'eta': 0.05, 'max_depth': 24, 'colsample_bytree': 0.8, 'subsample': 0.7},\n",
       " {'eta': 0.2, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 1.0}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_rel_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'eta': 0.1,\n",
       "  'max_depth': 24,\n",
       "  'colsample_bytree': 0.7,\n",
       "  'subsample': 0.7,\n",
       "  'num_class': 3},\n",
       " {'eta': 0.05,\n",
       "  'max_depth': 24,\n",
       "  'colsample_bytree': 0.8,\n",
       "  'subsample': 0.7,\n",
       "  'num_class': 3},\n",
       " {'eta': 0.2,\n",
       "  'max_depth': 6,\n",
       "  'colsample_bytree': 0.8,\n",
       "  'subsample': 1.0,\n",
       "  'num_class': 3},\n",
       " {'eta': 0.2,\n",
       "  'max_depth': 20,\n",
       "  'colsample_bytree': 1.0,\n",
       "  'subsample': 0.8,\n",
       "  'num_class': 3}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_cls_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple RandomSearchCV\n",
    "if global_cfg[\"train_multiple_models\"]:\n",
    "    best_rel_test_mean_rmse = 9999.0\n",
    "    best_cls_test_mean_mlogloss = 9999.0\n",
    "\n",
    "    best_rel_params = None\n",
    "    best_cls_params = None\n",
    "\n",
    "    for rel_params in array_rel_params:\n",
    "        rel_classifier = xgb.cv(rel_params, D_train_rel, num_boost_round=global_cfg[\"steps\"],\n",
    "                                nfold=5, metrics=\"rmse\", seed=1, early_stopping_rounds=5)\n",
    "\n",
    "        min_rel_rmse = rel_classifier[\"test-rmse-mean\"].min()\n",
    "        \n",
    "        if min_rel_rmse < best_rel_test_mean_rmse:\n",
    "            best_rel_test_mean_rmse = min_rel_rmse\n",
    "            best_rel_params = rel_params\n",
    "\n",
    "        del rel_classifier\n",
    "\n",
    "    for cls_params in array_cls_params:\n",
    "        cls_classifier = xgb.cv(cls_params, D_train_cls, num_boost_round=global_cfg[\"steps\"],\n",
    "                                nfold=5, metrics=\"mlogloss\", seed=1, early_stopping_rounds=5)\n",
    "\n",
    "        min_cls_mlogloss = cls_classifier[\"test-mlogloss-mean\"].min()\n",
    "        if min_cls_mlogloss < best_cls_test_mean_mlogloss:\n",
    "            best_cls_test_mean_mlogloss = min_cls_mlogloss\n",
    "            best_cls_params = cls_params\n",
    "\n",
    "        del cls_classifier\n",
    "\n",
    "\n",
    "    rel_classifier = xgb.train(best_rel_params, D_train_rel, global_cfg[\"steps\"])\n",
    "    cls_classifier = xgb.train(best_cls_params, D_train_cls, global_cfg[\"steps\"])\n",
    "\n",
    "    rel_classifier.save_model(\"../models/best_rel_classifier.json\")\n",
    "    cls_classifier.save_model(\"../models/best_cls_classifier.json\")\n",
    "        \n",
    "    os.makedirs(\"../models/\", exist_ok=True)\n",
    "\n",
    "    with open(\"../models/transform.pkl\", \"wb\") as f:\n",
    "        pickle.dump(tfidf_transform, f)\n",
    "\n",
    "else:\n",
    "    rel_classifier = xgb.train(rel_params, D_train_rel, global_cfg[\"steps\"])\n",
    "    cls_classifier = xgb.train(cls_params, D_train_cls, global_cfg[\"steps\"])\n",
    "\n",
    "    rel_classifier.save_model(\"../models/rel_classifier.json\")\n",
    "    cls_classifier.save_model(\"../models/cls_classifier.json\")\n",
    "        \n",
    "    os.makedirs(\"../models/\", exist_ok=True)\n",
    "\n",
    "    with open(\"../models/transform.pkl\", \"wb\") as f:\n",
    "        pickle.dump(tfidf_transform, f)\n",
    "\n",
    "del rel_classifier\n",
    "del cls_classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94b3bfe163e1866afd3b3db8ecc20722c474becdc4507c570d23aead5fc9a2bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
